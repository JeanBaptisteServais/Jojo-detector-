                                                                                                                                                                       
<strong><h1>STEP TWO</h1></strong>

So, we course the picture to search eventually an object from our database. <em>Here we have learn a plate.</em> and try to detect it.


We make a label file who say to us <strong>the name of the model, the name of the object, the label of this object, the name of his part and his dimension</strong>.
<br> 

For example : spoon spoon 1 handle,tank 50x50

Now we can detect objects in memory like that :

<p align="center">
  <img width="400" height="250" src="https://user-images.githubusercontent.com/54853371/67530531-9de92700-f6bf-11e9-9baa-2014c7e99217.jpg">
</p>


<strong>Finally</strong> we can recup the detection and try to make a reconciliation of object liaison from a situation. We serve to a plate in one situation for eat, so we search all others objects who can be use in the situation.

<strong>why did we do a label file ?</strong> We need the dimension for detect an object. For example a plate can be 50 cm width and 50 cm height but a spoon need to have for example 5 cm width and 20 cm height. Moreover, for a next version we can only detect the part of object for example a handle + a tank is a spoon, a handle + tine = fork !!







<br><br>


<strong><h1>STEP TWO</h1></strong>




<br><br>

<br><br>
3
<br><br>
4
<br><br>
5
<br><br>
6
<br><br>
7
<br><br>
8
<br><br>
résultats
<br><br>
amélioration
<br><br>
limits
<br><br>
pk ca ne marchera pas sur d'autres images (car je n'ai pas assez de temps blablabla)
<br><br>
